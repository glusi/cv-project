{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from Font_classifier import Font_classifier\n",
    "from download_h5py_db import download_file_from_google_drive\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "from utils import show_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_classifier_model(path):\n",
    "   \n",
    "    return Font_classifier(model)\n",
    "\n",
    "\n",
    "# def create_output():\n",
    "#     with open('train_lables.csv', 'w+', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         writer.writerow([\" \", \"image\", \"char\",\"Open Sans\",\"Sansation\",\"Titillium Web\",\"Ubuntu Mono\",\"Alex Brush\"])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test_data.h5'\n",
    "if not Path('test_data.h5').exists():\n",
    "    download_file_from_google_drive('1YwLcXqLArFSOtoepQw7nC1t4jC8CFxpI', FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'res//top_model.h5'\n",
    "model = load_model(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Font_classifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(db['data'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from utils import create_dirs, SIZE, get_image_data, crop_and_save, font_to_num\n",
    "from numpy import asarray, argmax, bincount,argwhere\n",
    "from h5py import File\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "np_utils.to_categorical(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, db_file):\n",
    "        db = File(db_file, 'r')   \n",
    "        size=SIZE\n",
    "        im_names = list(db['data'].keys())\n",
    "        num = 0\n",
    "        index = 0\n",
    "        # prediction_arr=[]\n",
    "        # images = []\n",
    "        # chars=[]\n",
    "        with open('test_lables.csv', 'w+', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\" \", \"image\", \"char\",\"Open Sans\",\"Sansation\",\"Titillium Web\",\"Ubuntu Mono\",\"Alex Brush\"])\n",
    "            for i in tqdm(range(0, len(im_names))):\n",
    "                im = im_names[i]\n",
    "                img, _, txts, charBBs, wordBBs = get_image_data(db, im, no_labels=True)\n",
    "                font_indx = 0 \n",
    "                char_indx = 0\n",
    "                for j in range(0, len(txts)):\n",
    "                    test_x = [] \n",
    "                    cropped = crop_and_save(img, wordBBs, j, size, None, im, num, True)\n",
    "                    test_x.append(cropped)\n",
    "                    num+=1            \n",
    "                    for k in range(0, len(txts[j])):\n",
    "                        word =  txts[j]\n",
    "                        cropped = crop_and_save(img, charBBs, char_indx, size, None, im, num, True)\n",
    "                        test_x.append(cropped)\n",
    "                        num+=1\n",
    "                        # char_indx+=1\n",
    "                        index += 1\n",
    "                    test_x = asarray(test_x, dtype=np.float32)\n",
    "                    reses = model.predict(test_x, verbose=0)\n",
    "                    maxes = argmax(reses, axis=1)\n",
    "                    prediction = bincount(maxes)\n",
    "                    prediction = argwhere(prediction==prediction.max())\n",
    "                    if (len(prediction)>1):\n",
    "                        reses_n = normalize(reses, axis=1, norm='l1')\n",
    "                        maxes_n = argmax(reses_n, axis=1)\n",
    "                        prediction = bincount(maxes_n)\n",
    "                        prediction = argwhere(prediction==prediction.max())\n",
    "                        if(len(prediction)>1):\n",
    "                            sum_p = np.sum(reses, axis=0)\n",
    "                            prediction = sum_p.argmax()\n",
    "                    for k in range(0, len(word)):\n",
    "                        a = []\n",
    "                        a.append(index)\n",
    "                        a.append(im)\n",
    "                        a.append(chr(word[k]))\n",
    "                        b = np_utils.to_categorical(prediction.item(), 5)\n",
    "                        b = np.concatenate((a,b[1:],[b[0]]))\n",
    "                        # print(b)\n",
    "                        writer.writerow(b)\n",
    "                        index+=1\n",
    "                        # prediction_arr.append(prediction.item())\n",
    "                        # images.append(im)\n",
    "                    font_indx += len(txts[j])\n",
    "        # return prediction_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [13:57<00:00,  1.20it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_y = predict(model, FILE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
