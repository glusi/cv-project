{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from download_h5py_db import download_file_from_google_drive\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "from utils import show_results\n",
    "from sklearn.preprocessing import normalize\n",
    "from numpy import asarray, argmax, bincount,argwhere\n",
    "from h5py import File\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from utils import create_dirs, SIZE, get_image_data, crop_and_save, font_to_num, is_not_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'test_data.h5'\n",
    "if not Path('test_data.h5').exists():\n",
    "    download_file_from_google_drive('1YwLcXqLArFSOtoepQw7nC1t4jC8CFxpI', FILE_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'res//top_model.h5'\n",
    "if not Path('test_data.h5').exists():\n",
    "    download_file_from_google_drive('TODO', path)\n",
    "model = load_model(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, db_file):\n",
    "        db = File(db_file, 'r')   \n",
    "        size=SIZE\n",
    "        im_names = list(db['data'].keys())\n",
    "        num = 0\n",
    "        index = 0\n",
    "        with open('test_lables.csv', 'w+', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\" \", \"image\", \"char\",\"Open Sans\",\"Sansation\",\"Titillium Web\",\"Ubuntu Mono\",\"Alex Brush\"])\n",
    "            for i in tqdm(range(0, len(im_names))):\n",
    "                im = im_names[i]\n",
    "                img, _, txts, charBBs, wordBBs = get_image_data(db, im, no_labels=True)\n",
    "                font_indx = 0 \n",
    "                char_indx = 0\n",
    "                for j in range(0, len(txts)):\n",
    "                    test_x = [] \n",
    "                    cropped = crop_and_save(img, wordBBs, j, size, None, im, num, True)\n",
    "                    test_x.append(cropped)\n",
    "                    num+=1            \n",
    "                    for k in range(0, len(txts[j])):\n",
    "                        if(is_not_dot(txts[j][k])):\n",
    "                            word =  txts[j]\n",
    "                            cropped = crop_and_save(img, charBBs, char_indx, size, None, im, num, True)\n",
    "                            test_x.append(cropped)\n",
    "                            num+=1\n",
    "                            index += 1\n",
    "                    test_x = asarray(test_x, dtype=np.float32)\n",
    "                    reses = model.predict_on_batch(test_x)\n",
    "                    maxes = np.argmax(reses, axis=1)\n",
    "                    prediction = np.bincount(maxes)\n",
    "                    prediction = np.argwhere(prediction==prediction.max())\n",
    "                    if(len(prediction)>1):\n",
    "                        sum_p = np.sum(reses, axis=0)\n",
    "                        prediction = sum_p.argmax()\n",
    "                    for k in range(0, len(word)):\n",
    "                        a = []\n",
    "                        a.append(index)\n",
    "                        a.append(im)\n",
    "                        a.append(chr(word[k]))\n",
    "                        b = np_utils.to_categorical(prediction.item(), 5)\n",
    "                        b = np.concatenate((a,b[1:],[b[0]]))\n",
    "                        writer.writerow(b)\n",
    "                        index+=1\n",
    "                    font_indx += len(txts[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1004/1004 [05:49<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_y = predict(model, FILE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
