{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Resizing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n",
    "SIZE=227\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    # points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    \n",
    "    # create an empty image with the same shape as the input image\n",
    "    # mask = np.zeros_like(img[:,:,0])\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    # bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    # cv2.fillPoly(mask, bounding_box, 255)\n",
    "    # apply the mask to the image\n",
    "    ####res = cv2.bitwise_and(img, mask)\n",
    "    # try1 = np.array(np.where(mask == 255, 255, 0), dtype=np.uint8)\n",
    "    # print(x)\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    # res2 = cv2.bitwise_and(img, inv_mask)\n",
    "    # bb2 = np.int32([[top_left_x, bot_right_y], [bot_right_x, bot_right_y],[bot_right_x,top_left_y], [top_left_x,top_left_y]])\n",
    "    # print(bb2)\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # # bb2 = np.array(frame, dtype=np.int32)\n",
    "    # cv2.fillPoly(mask2, bb2, (255, 255, 255))\n",
    "    # mask = mask[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    print(mask.shape)\"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_font(font):\n",
    "    if font == 0:\n",
    "        return b'Alex Brush'\n",
    "    elif font == 1:\n",
    "        return b'Titillium Web'\n",
    "    elif font == 2:\n",
    "        return b'Sansation'\n",
    "    elif font == 3:\n",
    "        return b'Open Sans'\n",
    "    else:\n",
    "        return b'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label(set, index):\n",
    "    line = set[index]\n",
    "    max = np.argmax(line)\n",
    "    print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_font(max):\n",
    "     print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo_from_set(set_x, set_y, index, font):\n",
    "    plt.imshow(set_x[index], cmap='gray')\n",
    "    plt.show()\n",
    "    print_font(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped = get_bb(img, bbs, index)\n",
    "    # _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.resize(cropped, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    # cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # # print(cropped.shape)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    # plt.imshow(cropped, cmap='gray')\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def create_dirs():\n",
    "    Path('main_directory').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Alex Brush').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Titillium Web').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Sansation').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Open Sans').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Ubuntu Mono').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    create_dirs()\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    num = 0\n",
    "    for i in tqdm(range(0, len(im_names)-1)):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg' \n",
    "            # print(path)\n",
    "            tf.keras.utils.save_img(path,cropped)\n",
    "            num+=1\n",
    "            # train_x.append(cropped)\n",
    "            # train_y.append(font_to_num(fonts[font_indx]))\n",
    "            \n",
    "            # plt.imshow(cropped, cmap='gray')\n",
    "            # plt.show()\n",
    "            # print(fonts[font_indx])\n",
    "            for k in range(0, len(txts[j])):\n",
    "                cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg'\n",
    "                # print(path)\n",
    "                tf.keras.utils.save_img(path,cropped)\n",
    "                num+=1\n",
    "                # train_x.append(cropped)\n",
    "                # train_y.append(font_to_num(fonts[font_indx]))\n",
    "                char_indx+=1\n",
    "                # plt.imshow(cropped, cmap='gray')\n",
    "                # plt.show()\n",
    "                # print(fonts[font_indx])\n",
    "            font_indx += len(txts[j])\n",
    "    print(num)\n",
    "    # return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_h5py_db import download_h5py_db\n",
    "if not Path(\"main_directory\").exists():\n",
    "    download_h5py_db()\n",
    "    get_data_set(SIZE)\n",
    "# train_x, train_y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def data_augmentation():\n",
    "    datagen =  ImageDataGenerator(\n",
    "        # horizontal_flip=True, rotation_range=10, fill_mode='reflect', \n",
    "        # shear_range=10, vertical_flip=False, channel_shift_range=1.0, brightness_range=(0.2, 0.8),\n",
    "     rescale=1/255,dtype='float32',validation_split=0.9)\n",
    "    # Path('augmented').mkdir(exist_ok=True)\n",
    "    it = datagen.flow_from_directory('main_directory', batch_size=18, subset='training', class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True)\n",
    "    val_it = datagen.flow_from_directory('main_directory', batch_size=18, subset='validation', class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True)\n",
    "    return it, val_it, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3794 images belonging to 5 classes.\n",
      "Found 34108 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "it, val_it, datagen = data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "Regularizer = l2(0.003)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
    "                        padding= 'valid', activation= 'relu',\n",
    "                        input_shape= (SIZE,SIZE,3),\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                        padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                padding= 'same', activation= 'relu',\n",
    "                kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                        padding= 'valid', data_format= None)) \n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                padding= 'same', activation= 'relu',\n",
    "                kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                padding= 'same', activation= 'relu',\n",
    "                kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                        padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(1000, activation= 'relu', activity_regularizer=Regularizer, kernel_regularizer=Regularizer))\n",
    "model.add(Dense(5, activation= 'softmax', activity_regularizer=Regularizer, kernel_regularizer=Regularizer))\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=3e-6, amsgrad=True, epsilon=0.1),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    # if epoch < 5:\n",
    "    #     return lr\n",
    "    # else:\n",
    "    return lr * 0.1 #tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 27, 27, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 5005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,383,349\n",
      "Trainable params: 62,383,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "211/211 [==============================] - 16s 59ms/step - loss: 6.7787 - accuracy: 0.2306\n",
      "Epoch 2/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.5204 - accuracy: 0.2654\n",
      "Epoch 3/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.4693 - accuracy: 0.2926\n",
      "Epoch 4/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.4438 - accuracy: 0.3137\n",
      "Epoch 5/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.4238 - accuracy: 0.3289\n",
      "Epoch 6/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.4085 - accuracy: 0.3595\n",
      "Epoch 7/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.3921 - accuracy: 0.3585\n",
      "Epoch 8/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.3774 - accuracy: 0.3711\n",
      "Epoch 9/15\n",
      "211/211 [==============================] - 12s 56ms/step - loss: 6.3624 - accuracy: 0.3848\n",
      "Epoch 10/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.3467 - accuracy: 0.4012\n",
      "Epoch 11/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.3318 - accuracy: 0.4096\n",
      "Epoch 12/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.3163 - accuracy: 0.4230\n",
      "Epoch 13/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.3015 - accuracy: 0.4270\n",
      "Epoch 14/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.2840 - accuracy: 0.4323\n",
      "Epoch 15/15\n",
      "211/211 [==============================] - 12s 55ms/step - loss: 6.2691 - accuracy: 0.4357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d71bd86940>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\n",
    "# datagen.fit(X_train)\n",
    "model.fit(it, epochs=15, verbose=1 , shuffle=True\n",
    "        #   ,callbacks=[callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1895 [================>.............] - ETA: 23s - loss: 6.3303 - accuracy: 0.3801"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(val_it)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1944\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   1945\u001b[0m ):\n\u001b[0;32m   1946\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1947\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   1948\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1949\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "score = model.evaluate(val_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 632/632 [==============================] - 150s 236ms/step - loss: 0.8984 - accuracy: 0.6251\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(val_it, verbose=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
