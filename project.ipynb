{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Resizing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n",
    "SIZE=227\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    # points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    \n",
    "    # create an empty image with the same shape as the input image\n",
    "    # mask = np.zeros_like(img[:,:,0])\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    # bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    # cv2.fillPoly(mask, bounding_box, 255)\n",
    "    # apply the mask to the image\n",
    "    ####res = cv2.bitwise_and(img, mask)\n",
    "    # try1 = np.array(np.where(mask == 255, 255, 0), dtype=np.uint8)\n",
    "    # print(x)\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    # res2 = cv2.bitwise_and(img, inv_mask)\n",
    "    # bb2 = np.int32([[top_left_x, bot_right_y], [bot_right_x, bot_right_y],[bot_right_x,top_left_y], [top_left_x,top_left_y]])\n",
    "    # print(bb2)\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # # bb2 = np.array(frame, dtype=np.int32)\n",
    "    # cv2.fillPoly(mask2, bb2, (255, 255, 255))\n",
    "    # mask = mask[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    print(mask.shape)\"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_font(font):\n",
    "    if font == 0:\n",
    "        return b'Alex Brush'\n",
    "    elif font == 1:\n",
    "        return b'Titillium Web'\n",
    "    elif font == 2:\n",
    "        return b'Sansation'\n",
    "    elif font == 3:\n",
    "        return b'Open Sans'\n",
    "    else:\n",
    "        return b'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label(set, index):\n",
    "    line = set[index]\n",
    "    max = np.argmax(line)\n",
    "    print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_font(max):\n",
    "     print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo_from_set(set_x, set_y, index, font):\n",
    "    plt.imshow(set_x[index], cmap='gray')\n",
    "    plt.show()\n",
    "    print_font(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped = get_bb(img, bbs, index)\n",
    "    # _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.resize(cropped, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    # cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # # print(cropped.shape)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    # plt.imshow(cropped, cmap='gray')\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def create_dirs():\n",
    "    Path('main_directory').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Alex Brush').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Titillium Web').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Sansation').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Open Sans').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Ubuntu Mono').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    create_dirs()\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in tqdm(range(0, len(im_names)-1)):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'.jpg'\n",
    "            # print(path)\n",
    "            tf.keras.utils.save_img(path,cropped)\n",
    "            # train_x.append(cropped)\n",
    "            # train_y.append(font_to_num(fonts[font_indx]))\n",
    "            \n",
    "            # plt.imshow(cropped, cmap='gray')\n",
    "            # plt.show()\n",
    "            # print(fonts[font_indx])\n",
    "            for k in range(0, len(txts[j])):\n",
    "                cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'.jpg'\n",
    "                # print(path)\n",
    "                tf.keras.utils.save_img(path,cropped)\n",
    "                # train_x.append(cropped)\n",
    "                # train_y.append(font_to_num(fonts[font_indx]))\n",
    "                char_indx+=1\n",
    "                # plt.imshow(cropped, cmap='gray')\n",
    "                # plt.show()\n",
    "                # print(fonts[font_indx])\n",
    "            font_indx += len(txts[j])\n",
    "    # return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_h5py_db import download_h5py_db\n",
    "if not Path(\"main_directory\").exists():\n",
    "    download_h5py_db()\n",
    "    get_data_set(SIZE)\n",
    "# train_x, train_y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def data_augmentation():\n",
    "    datagen =  ImageDataGenerator(horizontal_flip=True, rotation_range=10, fill_mode='reflect',\n",
    "     )\n",
    "    Path('augmented').mkdir(exist_ok=True)\n",
    "    it = datagen.flow_from_directory('main_directory', batch_size=30, \n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True)\n",
    "    return it, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it, datagen = data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
    "                        padding= 'valid', activation= 'relu',\n",
    "                        input_shape= (SIZE,SIZE,3),\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                        padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                padding= 'same', activation= 'relu',\n",
    "                kernel_initializer= 'he_normal'))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                        padding= 'valid', data_format= None)) \n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                padding= 'same', activation= 'relu',\n",
    "                kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                padding= 'same', activation= 'relu',\n",
    "                kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                        padding= 'valid', data_format= None))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(4096, activation= 'relu'))\n",
    "model.add(Dense(1000, activation= 'relu'))\n",
    "model.add(Dense(5, activation= 'softmax'))\n",
    "\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(0.00001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=10e-5) \n",
    "#tf.keras.optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#tf.keras.optimizers.Adam(learning_rate=10e-2, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(x_train, dtype='uint8')\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\n",
    "# datagen.fit(X_train)\n",
    "model.fit(it, epochs=20, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test)\n",
    "#np.random.shuffle(Y_test)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "predict = model.predict(X_test, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.513256847858429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 1\n",
    "plt.imshow(X_test[indx], cmap='gray')\n",
    "plt.show\n",
    "print(Y_test[indx])\n",
    "# print(predict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(X_test)):\n",
    "#     predict_index = np.argmax(predict[i])\n",
    "#     test_index = np.argmax(Y_test[i])\n",
    "#     if(test_index != predict_index):\n",
    "#         print(test_index)\n",
    "#         print(predict_index)\n",
    "#         print_photo_from_set(X_test, Y_test, i, test_index)\n",
    "#         print_font(predict_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_train[:7])\n",
    "# print(res) 0.5317240357398987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model \n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
