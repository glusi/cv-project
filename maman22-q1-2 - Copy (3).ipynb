{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    # points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    \n",
    "    # create an empty image with the same shape as the input image\n",
    "    # mask = np.zeros_like(img[:,:,0])\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    # bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    # cv2.fillPoly(mask, bounding_box, 255)\n",
    "    # apply the mask to the image\n",
    "    ####res = cv2.bitwise_and(img, mask)\n",
    "    # try1 = np.array(np.where(mask == 255, 255, 0), dtype=np.uint8)\n",
    "    # print(x)\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    # res2 = cv2.bitwise_and(img, inv_mask)\n",
    "    # bb2 = np.int32([[top_left_x, bot_right_y], [bot_right_x, bot_right_y],[bot_right_x,top_left_y], [top_left_x,top_left_y]])\n",
    "    # print(bb2)\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # # bb2 = np.array(frame, dtype=np.int32)\n",
    "    # cv2.fillPoly(mask2, bb2, (255, 255, 255))\n",
    "    # mask = mask[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    print(mask.shape)\"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_font(font):\n",
    "    if font == 0:\n",
    "        return b'Alex Brush'\n",
    "    elif font == 1:\n",
    "        return b'Titillium Web'\n",
    "    elif font == 2:\n",
    "        return b'Sansation'\n",
    "    elif font == 3:\n",
    "        return b'Open Sans'\n",
    "    else:\n",
    "        return b'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label(set, index):\n",
    "    line = set[index]\n",
    "    max = np.argmax(line)\n",
    "    print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_font(max):\n",
    "     print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo_from_set(set_x, set_y, index, font):\n",
    "    plt.imshow(set_x[index], cmap='gray')\n",
    "    plt.show()\n",
    "    print_font(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped = get_bb(img, bbs, index)\n",
    "    # _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.resize(cropped, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # # print(cropped.shape)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    # plt.imshow(cropped, cmap='gray')\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def create_dirs():\n",
    "    Path('main_directory').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Alex Brush').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Titillium Web').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Sansation').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Open Sans').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Ubuntu Mono').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    create_dirs()\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in range(0, len(im_names)-1):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'.jpg'\n",
    "            # print(path)\n",
    "            tf.keras.utils.save_img(path,cropped)\n",
    "            # train_x.append(cropped)\n",
    "            # train_y.append(font_to_num(fonts[font_indx]))\n",
    "            \n",
    "            # plt.imshow(cropped, cmap='gray')\n",
    "            # plt.show()\n",
    "            # print(fonts[font_indx])\n",
    "            for k in range(0, len(txts[j])):\n",
    "                cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'.jpg'\n",
    "                # print(path)\n",
    "                tf.keras.utils.save_img(path,cropped)\n",
    "                # train_x.append(cropped)\n",
    "                # train_y.append(font_to_num(fonts[font_indx]))\n",
    "                char_indx+=1\n",
    "                # plt.imshow(cropped, cmap='gray')\n",
    "                # plt.show()\n",
    "                # print(fonts[font_indx])\n",
    "            font_indx += len(txts[j])\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE=256\n",
    "# train_x, train_y = get_data_set(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = np.asarray(train_x, dtype=\"float\") / 255.0\n",
    "# plt.imshow(train_x[3], cmap='gray')\n",
    "# print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the set for train and validation\n",
    "# x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = np_utils.to_categorical(y_train, 5)\n",
    "# Y_test = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(x_train)\n",
    "# Y_train = np.array(Y_train)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# plt.imshow(X_train[2], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing_function(img):\n",
    "#     img = tf.image.resize(img, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "#     img = tf.image.rgb_to_grayscale(img)\n",
    "#     # img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def data_augmentation():\n",
    "    datagen =  ImageDataGenerator(horizontal_flip=True, rotation_range=10, fill_mode='reflect',  \n",
    "     )\n",
    "    Path('augmented').mkdir(exist_ok=True)\n",
    "    it = datagen.flow_from_directory('main_directory', batch_size=10, save_to_dir='augmented')\n",
    "    return it, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3560 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "it, datagen = data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_mean = X_train.mean(axis=0)\n",
    "# datagen.fit(X_train - X_mean)\n",
    "# datagen.mean = X_train.mean(axis=0)\n",
    "# datagen.std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Open Sans'\n"
     ]
    }
   ],
   "source": [
    "# while(it!=None):\n",
    "img, label = it.next()\n",
    "#     # print(img)\n",
    "#     if(num_to_font(np.argmax(label))==b'Titillium Web'):\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "plt.show()\n",
    "print(num_to_font(np.argmax(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Resizing\n",
    "\n",
    "# SIZE=100\n",
    "visible = Input(shape=(SIZE,SIZE,1))\n",
    "conv = Conv2D(32, kernel_size=4, activation='relu', padding='same')(visible)\n",
    "pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "x = Dropout(0.25)(pool)\n",
    "conv = Conv2D(32, kernel_size=4, activation='relu', padding='same')(x)\n",
    "pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "x = Dropout(0.25)(pool)\n",
    "conv = Conv2D(64, kernel_size=4, activation='relu', padding='same')(x)\n",
    "pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "# x = Dropout(0.25)(pool)\n",
    "# conv = Conv2D(31, kernel_size=4, activation='relu')(x)\n",
    "# pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "# x = Dropout(0.25)(pool)\n",
    "# conv = Conv2D(16, kernel_size=4, activation='relu')(x)\n",
    "# pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "# x = Dropout(0.25)(pool)\n",
    "flat = Flatten()(x)\n",
    "hidden1 = Dense(50, activation='sigmoid')(flat)\n",
    "output = Dense(5, activation='sigmoid')(hidden1)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "# print(model.summary())\n",
    "# plot graph\n",
    "# plot_model(model, to_file='convolutional_neural_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=10e-5) \n",
    "#tf.keras.optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#tf.keras.optimizers.Adam(learning_rate=10e-2, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(x_train, dtype='uint8')\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  5/356 [..............................] - ETA: 1:22 - loss: 1.8452 - accuracy: 0.1400 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[108], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# datagen.fit(X_train)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mfit(it, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[callback])\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\n",
    "# datagen.fit(X_train)\n",
    "model.fit(it, epochs=20, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test)\n",
    "#np.random.shuffle(Y_test)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "predict = model.predict(X_test, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.513256847858429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 1\n",
    "plt.imshow(X_test[indx], cmap='gray')\n",
    "plt.show\n",
    "print(Y_test[indx])\n",
    "# print(predict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(X_test)):\n",
    "#     predict_index = np.argmax(predict[i])\n",
    "#     test_index = np.argmax(Y_test[i])\n",
    "#     if(test_index != predict_index):\n",
    "#         print(test_index)\n",
    "#         print(predict_index)\n",
    "#         print_photo_from_set(X_test, Y_test, i, test_index)\n",
    "#         print_font(predict_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_train[:7])\n",
    "# print(res) 0.5317240357398987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model \n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
