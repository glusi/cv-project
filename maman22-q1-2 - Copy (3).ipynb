{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    # points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    \n",
    "    # create an empty image with the same shape as the input image\n",
    "    # mask = np.zeros_like(img[:,:,0])\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    # bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    # cv2.fillPoly(mask, bounding_box, 255)\n",
    "    # apply the mask to the image\n",
    "    ####res = cv2.bitwise_and(img, mask)\n",
    "    # try1 = np.array(np.where(mask == 255, 255, 0), dtype=np.uint8)\n",
    "    # print(x)\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    # res2 = cv2.bitwise_and(img, inv_mask)\n",
    "    # bb2 = np.int32([[top_left_x, bot_right_y], [bot_right_x, bot_right_y],[bot_right_x,top_left_y], [top_left_x,top_left_y]])\n",
    "    # print(bb2)\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # # bb2 = np.array(frame, dtype=np.int32)\n",
    "    # cv2.fillPoly(mask2, bb2, (255, 255, 255))\n",
    "    # mask = mask[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    print(mask.shape)\"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_font(font):\n",
    "    if font == 0:\n",
    "        return b'Alex Brush'\n",
    "    elif font == 1:\n",
    "        return b'Titillium Web'\n",
    "    elif font == 2:\n",
    "        return b'Sansation'\n",
    "    elif font == 3:\n",
    "        return b'Open Sans'\n",
    "    else:\n",
    "        return b'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label(set, index):\n",
    "    line = set[index]\n",
    "    max = np.argmax(line)\n",
    "    print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_font(max):\n",
    "     print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo_from_set(set_x, set_y, index, font):\n",
    "    plt.imshow(set_x[index], cmap='gray')\n",
    "    plt.show()\n",
    "    print_font(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped = get_bb(img, bbs, index)\n",
    "    # _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.resize(cropped, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # # print(cropped.shape)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    # plt.imshow(cropped, cmap='gray')\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in range(0, len(im_names)-1):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            train_x.append(cropped)\n",
    "            train_y.append(font_to_num(fonts[font_indx]))\n",
    "            \n",
    "            # plt.imshow(cropped, cmap='gray')\n",
    "            # plt.show()\n",
    "            # print(fonts[font_indx])\n",
    "            for k in range(0, len(txts[j])):\n",
    "                cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                train_x.append(cropped)\n",
    "                train_y.append(font_to_num(fonts[font_indx]))\n",
    "                char_indx+=1\n",
    "                # plt.imshow(cropped, cmap='gray')\n",
    "                # plt.show()\n",
    "                # print(fonts[font_indx])\n",
    "            font_indx += len(txts[j])\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m SIZE\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m\n\u001b[1;32m----> 2\u001b[0m train_x, train_y \u001b[39m=\u001b[39m get_data_set(SIZE)\n",
      "Cell \u001b[1;32mIn[13], line 25\u001b[0m, in \u001b[0;36mget_data_set\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m# plt.imshow(cropped, cmap='gray')\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39m# plt.show()\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[39m# print(fonts[font_indx])\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(txts[j])):\n\u001b[1;32m---> 25\u001b[0m     cropped \u001b[39m=\u001b[39m prepare_img(img, charBBs, char_indx, size)\n\u001b[0;32m     26\u001b[0m     train_x\u001b[39m.\u001b[39mappend(cropped)\n\u001b[0;32m     27\u001b[0m     train_y\u001b[39m.\u001b[39mappend(font_to_num(fonts[font_indx]))\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mprepare_img\u001b[1;34m(img, bbs, index, size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# print(cropped.shape)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m cropped \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mresize(cropped, (size, size), method\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mResizeMethod\u001b[39m.\u001b[39mNEAREST_NEIGHBOR)\n\u001b[1;32m----> 6\u001b[0m cropped \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mrgb_to_grayscale(cropped)\n\u001b[0;32m      7\u001b[0m \u001b[39m# # print(cropped.shape)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m cropped \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mconvert_image_dtype(cropped, tf\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7209\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7208\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7209\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul]"
     ]
    }
   ],
   "source": [
    "SIZE=256\n",
    "train_x, train_y = get_data_set(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.asarray(train_x, dtype=\"float\") / 255.0\n",
    "plt.imshow(train_x[3], cmap='gray')\n",
    "# print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the set for train and validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 5)\n",
    "Y_test = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(x_train)\n",
    "Y_train = np.array(Y_train)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# plt.imshow(X_train[2], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_function(img):\n",
    "    img = tf.image.resize(img, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    img = tf.image.rgb_to_grayscale(img)\n",
    "    # img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def data_augmentation(X, Y):\n",
    "    datagen =  ImageDataGenerator(horizontal_flip=True, rotation_range=10, fill_mode='reflect',  \n",
    "     )\n",
    "    it = datagen.flow(X, Y, batch_size=10, shuffle=True)\n",
    "    return it, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it, datagen = data_augmentation(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_mean = X_train.mean(axis=0)\n",
    "# datagen.fit(X_train - X_mean)\n",
    "datagen.mean = X_train.mean(axis=0)\n",
    "datagen.std = X_train.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# while(it!=None):\n",
    "img, label = it.next()\n",
    "#     # print(img)\n",
    "#     if(num_to_font(np.argmax(label))==b'Titillium Web'):\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "plt.show()\n",
    "print(num_to_font(np.argmax(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Resizing\n",
    "# SIZE=100\n",
    "visible = Input(shape=(SIZE,SIZE,1))\n",
    "conv = Conv2D(32, kernel_size=4, activation='relu')(visible)\n",
    "pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "x = Dropout(0.25)(pool)\n",
    "conv = Conv2D(32, kernel_size=4, activation='relu')(x)\n",
    "pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "x = Dropout(0.25)(pool)\n",
    "conv = Conv2D(64, kernel_size=4, activation='relu')(x)\n",
    "pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "# x = Dropout(0.25)(pool)\n",
    "# conv = Conv2D(31, kernel_size=4, activation='relu')(x)\n",
    "# pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "# x = Dropout(0.25)(pool)\n",
    "# conv = Conv2D(16, kernel_size=4, activation='relu')(x)\n",
    "# pool = MaxPooling2D(pool_size=(2, 2))(conv)\n",
    "# x = Dropout(0.25)(pool)\n",
    "flat = Flatten()(x)\n",
    "hidden1 = Dense(50, activation='sigmoid')(flat)\n",
    "output = Dense(5, activation='sigmoid')(hidden1)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "# print(model.summary())\n",
    "# plot graph\n",
    "# plot_model(model, to_file='convolutional_neural_network.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 1:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=10e-5) \n",
    "#tf.keras.optimizers.SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#tf.keras.optimizers.Adam(learning_rate=10e-2, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(x_train, dtype='uint8')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\n",
    "# datagen.fit(X_train)\n",
    "model.fit(it, epochs=20, verbose=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test)\n",
    "#np.random.shuffle(Y_test)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "predict = model.predict(X_test, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.513256847858429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 1\n",
    "plt.imshow(X_test[indx], cmap='gray')\n",
    "plt.show\n",
    "print(Y_test[indx])\n",
    "# print(predict[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(X_test)):\n",
    "#     predict_index = np.argmax(predict[i])\n",
    "#     test_index = np.argmax(Y_test[i])\n",
    "#     if(test_index != predict_index):\n",
    "#         print(test_index)\n",
    "#         print(predict_index)\n",
    "#         print_photo_from_set(X_test, Y_test, i, test_index)\n",
    "#         print_font(predict_index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_train[:7])\n",
    "# print(res) 0.5317240357398987"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model \n",
    "#tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
