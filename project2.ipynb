{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, BatchNormalization, ZeroPadding2D, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Resizing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n",
    "SIZE=224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_training_curve(history):\n",
    "\t\"\"\"\n",
    "\tDraw training curve\n",
    "\tParameters:\n",
    "\t\thistory - contains loss and accuracy from training\n",
    "\tReturns:\n",
    "\t\tNone\n",
    "\t\"\"\"\n",
    "\tplt.figure(1)\n",
    "\n",
    "\t# History for accuracy\n",
    "\tplt.subplot(211)\n",
    "\tplt.plot(history.history['accuracy'])\n",
    "\tplt.plot(history.history['val_accuracy'])\n",
    "\tplt.title('model accuracy')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\t# History for loss\n",
    "\tplt.subplot(212)\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title('model loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    # points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    \n",
    "    # create an empty image with the same shape as the input image\n",
    "    # mask = np.zeros_like(img[:,:,0])\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    # bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    # cv2.fillPoly(mask, bounding_box, 255)\n",
    "    # apply the mask to the image\n",
    "    ####res = cv2.bitwise_and(img, mask)\n",
    "    # try1 = np.array(np.where(mask == 255, 255, 0), dtype=np.uint8)\n",
    "    # print(x)\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    # res2 = cv2.bitwise_and(img, inv_mask)\n",
    "    # bb2 = np.int32([[top_left_x, bot_right_y], [bot_right_x, bot_right_y],[bot_right_x,top_left_y], [top_left_x,top_left_y]])\n",
    "    # print(bb2)\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # # bb2 = np.array(frame, dtype=np.int32)\n",
    "    # cv2.fillPoly(mask2, bb2, (255, 255, 255))\n",
    "    # mask = mask[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    print(mask.shape)\"\"\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_font(font):\n",
    "    if font == 0:\n",
    "        return b'Alex Brush'\n",
    "    elif font == 1:\n",
    "        return b'Titillium Web'\n",
    "    elif font == 2:\n",
    "        return b'Sansation'\n",
    "    elif font == 3:\n",
    "        return b'Open Sans'\n",
    "    else:\n",
    "        return b'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label(set, index):\n",
    "    line = set[index]\n",
    "    max = np.argmax(line)\n",
    "    print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_font(max):\n",
    "     print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo_from_set(set_x, set_y, index, font):\n",
    "    plt.imshow(set_x[index], cmap='gray')\n",
    "    plt.show()\n",
    "    print_font(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped = get_bb(img, bbs, index)\n",
    "    # _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.resize(cropped, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    # cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # # print(cropped.shape)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    # plt.imshow(cropped, cmap='gray')\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def create_dirs():\n",
    "    Path('main_directory').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Alex Brush').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Titillium Web').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Sansation').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Open Sans').mkdir(parents=True, exist_ok=True)\n",
    "    Path('main_directory/Ubuntu Mono').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_num_or_letter(inp):\n",
    "    res= ((inp >= ord('a') and inp <= ord('z')) or (inp >= ord('A') and inp <= ord('Z'))) or (inp>=ord('0') and inp<=ord('9'))\n",
    "    # print(chr(inp)+\"=\"+str(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    create_dirs()\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    num = 0\n",
    "    for i in tqdm(range(0, len(im_names)-1)):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg' \n",
    "            # print(path)\n",
    "            tf.keras.utils.save_img(path,cropped)\n",
    "            num+=1\n",
    "            # train_x.append(cropped)\n",
    "            # train_y.append(font_to_num(fonts[font_indx]))\n",
    "            \n",
    "            # plt.imshow(cropped, cmap='gray')\n",
    "            # plt.show()\n",
    "            # print(fonts[font_indx])\n",
    "            for k in range(0, len(txts[j])):\n",
    "                if(is_num_or_letter(txts[j][k])):\n",
    "                    cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                    path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg'\n",
    "                    # print(path)\n",
    "                    tf.keras.utils.save_img(path,cropped)\n",
    "                    num+=1\n",
    "                    # train_x.append(cropped)\n",
    "                    # train_y.append(font_to_num(fonts[font_indx]))\n",
    "                char_indx+=1\n",
    "                    # plt.imshow(cropped, cmap='gray')\n",
    "                    # plt.show()\n",
    "                    # print(fonts[font_indx])\n",
    "            font_indx += len(txts[j])\n",
    "    print(num)\n",
    "    # return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from download_h5py_db import download_h5py_db\n",
    "if not Path(\"main_directory\").exists():\n",
    "    download_h5py_db()\n",
    "    get_data_set(SIZE)\n",
    "# train_x, train_y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def data_augmentation():\n",
    "    datagen =  ImageDataGenerator(\n",
    "        horizontal_flip=True, rotation_range=180, fill_mode='reflect', channel_shift_range=0.8,#\n",
    "         shear_range=30,vertical_flip=False, brightness_range=(0.2, 0.8),# \n",
    "     rescale=1/255,dtype='float32',validation_split=0.25)\n",
    "    # Path('augmented').mkdir(exist_ok=True)\n",
    "    it = datagen.flow_from_directory('main_directory', batch_size=18, subset='training', class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True, seed=1, keep_aspect_ratio=True)\n",
    "    val_it = datagen.flow_from_directory('main_directory', batch_size=18, subset='validation', class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True)\n",
    "    return it, val_it, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27011 images belonging to 5 classes.\n",
      "Found 9000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "it, val_it, datagen = data_augmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense, GlobalMaxPooling2D\n\u001b[0;32m      5\u001b[0m input_t \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(SIZE,SIZE,\u001b[39m3\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m resnet_model \u001b[39m=\u001b[39m ResNet50(include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m                          input_shape\u001b[39m=\u001b[39;49minput_t,\n\u001b[0;32m      8\u001b[0m                         weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m resnet_model\u001b[39m.\u001b[39mlayers[:\u001b[39m143\u001b[39m]:\n\u001b[0;32m     10\u001b[0m         layer\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\applications\\resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[0;32m    518\u001b[0m     x \u001b[39m=\u001b[39m stack1(x, \u001b[39m256\u001b[39m, \u001b[39m6\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv4\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    519\u001b[0m     \u001b[39mreturn\u001b[39;00m stack1(x, \u001b[39m512\u001b[39m, \u001b[39m3\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconv5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 521\u001b[0m \u001b[39mreturn\u001b[39;00m ResNet(\n\u001b[0;32m    522\u001b[0m     stack_fn,\n\u001b[0;32m    523\u001b[0m     \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    524\u001b[0m     \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mresnet50\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    526\u001b[0m     include_top,\n\u001b[0;32m    527\u001b[0m     weights,\n\u001b[0;32m    528\u001b[0m     input_tensor,\n\u001b[0;32m    529\u001b[0m     input_shape,\n\u001b[0;32m    530\u001b[0m     pooling,\n\u001b[0;32m    531\u001b[0m     classes,\n\u001b[0;32m    532\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    533\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\applications\\resnet.py:159\u001b[0m, in \u001b[0;36mResNet\u001b[1;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    154\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIf using `weights` as `\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m` with `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m as true, `classes` should be 1000\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    158\u001b[0m \u001b[39m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m input_shape \u001b[39m=\u001b[39m imagenet_utils\u001b[39m.\u001b[39;49mobtain_input_shape(\n\u001b[0;32m    160\u001b[0m     input_shape,\n\u001b[0;32m    161\u001b[0m     default_size\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m,\n\u001b[0;32m    162\u001b[0m     min_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m    163\u001b[0m     data_format\u001b[39m=\u001b[39;49mbackend\u001b[39m.\u001b[39;49mimage_data_format(),\n\u001b[0;32m    164\u001b[0m     require_flatten\u001b[39m=\u001b[39;49minclude_top,\n\u001b[0;32m    165\u001b[0m     weights\u001b[39m=\u001b[39;49mweights,\n\u001b[0;32m    166\u001b[0m )\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m input_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     img_input \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\applications\\imagenet_utils.py:374\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[1;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    368\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mWhen setting `include_top=True` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    369\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mand loading `imagenet` weights, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`input_shape` should be \u001b[39m\u001b[39m{\u001b[39;00mdefault_shape\u001b[39m}\u001b[39;00m\u001b[39m.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived: input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m             )\n\u001b[0;32m    373\u001b[0m     \u001b[39mreturn\u001b[39;00m default_shape\n\u001b[1;32m--> 374\u001b[0m \u001b[39mif\u001b[39;00m input_shape:\n\u001b[0;32m    375\u001b[0m     \u001b[39mif\u001b[39;00m data_format \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mchannels_first\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    376\u001b[0m         \u001b[39mif\u001b[39;00m input_shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\keras_tensor.py:244\u001b[0m, in \u001b[0;36mKerasTensor.__len__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 244\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mKeras symbolic inputs/outputs do not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mimplement `__len__`. You may be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtrying to pass Keras symbolic inputs/outputs \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto a TF API that does not register dispatching, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpreventing Keras from automatically \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mconverting the API call to a lambda layer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    251\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39min the Functional Model. This error will also get raised \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mif you try asserting a symbolic input/output directly.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: Keras symbolic inputs/outputs do not implement `__len__`. You may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model. This error will also get raised if you try asserting a symbolic input/output directly."
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.layers import Dense, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "resnet_model = ResNet50(include_top=False,\n",
    "                         input_shape=(SIZE, SIZE, 3),\n",
    "                        weights='imagenet')\n",
    "for layer in resnet_model.layers[:143]:\n",
    "        layer.trainable = False\n",
    "# for i, layer in enumerate(resnet_model.layers):\n",
    "#         print(i, layer.name, \"-\", layer.trainable)\n",
    "model = Sequential()\n",
    "model.add(resnet_model)\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(5, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath='try.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_1/flatten_1/Reshape' defined at (most recent call last):\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\simon\\AppData\\Local\\Temp\\ipykernel_10644\\3091831251.py\", line 3, in <module>\n      history = model.fit(it, epochs=10, verbose=1 , shuffle=True, validation_data=val_it\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\layers\\reshaping\\flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_1/flatten_1/Reshape'\nInput to reshape is a tensor with 2359296 values, but the requested shape requires a multiple of 100352\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_train_function_26372]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# datagen.fit(X_train)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(it, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m , shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, validation_data\u001b[39m=\u001b[39;49mval_it\n\u001b[0;32m      4\u001b[0m         \u001b[39m#   ,callbacks=[callback]\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m           )\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_1/flatten_1/Reshape' defined at (most recent call last):\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 1041, in launch_instance\n      app.start()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\simon\\AppData\\Local\\Temp\\ipykernel_10644\\3091831251.py\", line 3, in <module>\n      history = model.fit(it, epochs=10, verbose=1 , shuffle=True, validation_data=val_it\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\layers\\reshaping\\flatten.py\", line 104, in call\n      return tf.reshape(inputs, flattened_shape)\nNode: 'sequential_1/flatten_1/Reshape'\nInput to reshape is a tensor with 2359296 values, but the requested shape requires a multiple of 100352\n\t [[{{node sequential_1/flatten_1/Reshape}}]] [Op:__inference_train_function_26372]"
     ]
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=16, epochs=20, verbose=1)\n",
    "# datagen.fit(X_train)\n",
    "history = model.fit(it, epochs=10, verbose=1 , shuffle=True, validation_data=val_it\n",
    "        #   ,callbacks=[callback]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(val_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "632/632 [==============================] - 161s 254ms/step - loss: 0.2479 - accuracy: 0.6977\n",
    "632/632 [==============================] - 53s 82ms/step - loss: 1.6858 - accuracy: 0.5157\n",
    "632/632 [==============================] - 150s 236ms/step - loss: 0.8984 - accuracy: 0.6251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_training_curve(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(val_it, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
