{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches\n",
    "from keras.layers import Conv2D, MaxPooling2D , UpSampling2D ,Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_bb(img, bbs, indx):\n",
    "#     x1 = int(bbs[0,0,indx])\n",
    "#     y1 = int(bbs[1,0,indx])\n",
    "#     x2 = int(bbs[0,1,indx])\n",
    "#     y2 = int(bbs[1,1,indx])\n",
    "#     x3 = int(bbs[0,2,indx])\n",
    "#     y3 = int(bbs[1,2,indx])\n",
    "#     x4 = int(bbs[0,3,indx])\n",
    "#     y4 = int(bbs[1,3,indx])\n",
    "#     # calculate bounding rectangle\n",
    "#     top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "#     top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "#     bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "#     bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "#     points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "#     # create an empty image with the same shape as the input image\n",
    "#     mask = np.zeros_like((img))\n",
    "#     # create a list of the bounding box points in the correct format\n",
    "#     bounding_box = np.array([points], dtype=np.int32)\n",
    "#     # fill the area inside the bounding box with white\n",
    "#     cv2.fillPoly(mask, bounding_box, (255, 255, 255))\n",
    "#     # apply the mask to the image\n",
    "#     res = cv2.bitwise_and(img, mask)[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "#     #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "#     #flipping\n",
    "#     \"\"\"\"if(x2 < x1):\n",
    "#         res = cv2.flip(res, 1)\n",
    "#     if(y2 < y1):\n",
    "#         res = cv2.flip(res, 0)\n",
    "#     plt.imshow(res)\n",
    "#     plt.show()\"\"\"\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    # create an empty image with the same shape as the input image\n",
    "    mask = np.zeros_like((img))\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    cv2.fillPoly(mask, bounding_box, (255, 255, 255))\n",
    "    inv_mask = cv2.bitwise_not(mask)\n",
    "    gray_mask = cv2.cvtColor(inv_mask, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # cv2.fillPoly(mask2, [top_left_y:bot_right_y+1, top_left_x:bot_right_x+1], (255, 255, 255))\n",
    "    \n",
    "\n",
    "    res1 = cv2.inpaint(img, gray_mask, 1, cv2.INPAINT_NS)\n",
    "    # plt.imshow(res1)\n",
    "    # plt.show()\n",
    "    # apply the mask to the image\n",
    "    res = cv2.bitwise_and(img, mask)\n",
    "    res = cv2.bitwise_and(img, res1)[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(res)\"\"\"\n",
    "    plt.show()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scale_resize_image(image, size):\n",
    "#     # image = tf.image.convert_image_dtype(image, tf.float32) # equivalent to dividing image pixels by 255\n",
    "#     #image = image / 255.0\n",
    "#     image = tf.image.resize(image, (size, size)) # Resizing the image to 224x224 dimention\n",
    "#     return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped = get_bb(img, bbs, index)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    cropped = tf.image.resize(cropped, (size, size))\n",
    "    cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # cropped = tf.cast(cropped, tf.uint8)\n",
    "    # cropped = cv2.GaussianBlur(cropped.numpy(), (3,3), 0)\n",
    "    # print(cropped)\n",
    "    # cropped = tf.image.convert_image_dtype(cropped, tf.uint8)\n",
    "    # cropped = cv2.Canny(cropped.numpy(), 0, 3000)\n",
    "\n",
    "    # cropped = cv2.Canny(cropped, 200, 202)\n",
    "    # cropped = tf.convert_to_tensor(cropped, dtype=tf.float32)\n",
    "\n",
    "    #cropped -= cropped.mean()\n",
    "    # img = tf.ones([size, size, 3], dtype=tf.float32) #(100, 100, 3)\n",
    "    # mean = tf.constant([1, 2, 3], dtype=tf.float32) # (3)\n",
    "    # mean = tf.reshape(mean, [1, 1, 3])\n",
    "    # img_m = img - mean\n",
    "    #cropped = cv2.cvtColor(np.asarray(cropped, cv2.COLOR_BGR2GRAY))\n",
    "    # print(cropped)\n",
    "   \n",
    "    # \n",
    "    # \n",
    "    # res = np.squeeze(cropped)\n",
    "    # res = (cropped * 255).astype(np.uint8)\n",
    "    \n",
    "    # res = cv2.GaussianBlur(res, (3,3), 0)\n",
    "    # # print(res.dtype)\n",
    "    # # res = np.uint8(res)\n",
    "    # res = cv2.Canny(res, 0, 3000)\n",
    "    # # print(res)\n",
    "    # plt.imshow(cropped, cmap='gray' )\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in range(0, len(im_names)-1):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            train_x.append(cropped)\n",
    "            train_y.append(font_to_num(fonts[font_indx]))\n",
    "            font_indx += len(txts[j])\n",
    "            #plt.imshow(cropped)\n",
    "            #plt.show()\n",
    "            for k in range(0, len(txts[j])):\n",
    "                cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                train_x.append(cropped)\n",
    "                train_y.append(font_to_num(fonts[char_indx]))\n",
    "                char_indx+=1\n",
    "                #plt.imshow(cropped)\n",
    "                #plt.show()\n",
    "    return train_x, train_y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18312\\1908900692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_data_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18312\\3757837678.py\u001b[0m in \u001b[0;36mget_data_set\u001b[1;34m(size)\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtxts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcharBBs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchar_indx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mtrain_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mtrain_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont_to_num\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfonts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchar_indx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18312\\3952845871.py\u001b[0m in \u001b[0;36mprepare_img\u001b[1;34m(img, bbs, index, size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprepare_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_bb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_image_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcropped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrgb_to_grayscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18312\\3482280785.py\u001b[0m in \u001b[0;36mget_bb\u001b[1;34m(img, bbs, indx)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mres1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minpaint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINPAINT_NS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;31m# plt.imshow(res1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x, train_y = get_data_set(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x = np.asarray(train_x, dtype=\"float\") / 255.0\n",
    "#print(train_x)\n",
    "#print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the set for train and validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 5)\n",
    "Y_test = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#   tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#   tf.keras.layers.RandomRotation(0.2),\n",
    "# ])\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', padding='same', input_shape=(64,64,1)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import BatchNormalization\n",
    "# #  model = Sequential([\n",
    "# #   tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "# #   tf.keras.layers.RandomRotation(0.2),\n",
    "# # ])\n",
    "# model = Sequential()\n",
    "# # Cu Layers \n",
    "# model.add(Conv2D(64, kernel_size=(48, 48), activation='relu', input_shape=(64,64,1)))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(128, kernel_size=(24, 24), activation='relu'))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2DTranspose(128, (24,24), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "# model.add(UpSampling2D(size=(2, 2)))\n",
    "# model.add(Conv2DTranspose(64, (12,12), strides = (2,2), activation = 'relu', padding='same', kernel_initializer='uniform'))\n",
    "# model.add(UpSampling2D(size=(2, 2)))\n",
    "# #Cs Layers\n",
    "# model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "# model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "# model.add(Conv2D(256, kernel_size=(12, 12), activation='relu'))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(4096, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(4096,activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(2383,activation='relu'))\n",
    "# model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(x_train)\n",
    "Y_train = np.array(Y_train)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# plt.imshow(X_train[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1896/1896 [==============================] - 11s 5ms/step - loss: 1.6055 - accuracy: 0.2480\n",
      "Epoch 2/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.5602 - accuracy: 0.3040\n",
      "Epoch 3/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.5011 - accuracy: 0.3421\n",
      "Epoch 4/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.4543 - accuracy: 0.3662\n",
      "Epoch 5/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.4159 - accuracy: 0.3834\n",
      "Epoch 6/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.3874 - accuracy: 0.3962\n",
      "Epoch 7/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.3674 - accuracy: 0.4077\n",
      "Epoch 8/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.3572 - accuracy: 0.4123\n",
      "Epoch 9/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.3331 - accuracy: 0.4239\n",
      "Epoch 10/10\n",
      "1896/1896 [==============================] - 10s 5ms/step - loss: 1.3259 - accuracy: 0.4321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0b1466df0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=16, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test)\n",
    "#np.random.shuffle(Y_test)\n",
    "score = model.evaluate(X_test[:1000], Y_test[:1000], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2389733791351318 / Test accuracy: 0.4880000054836273\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_train[:7])\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model \n",
    "#tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d12e26f72a40d5c48233c54861fca038d6a92135fc0e5e920944e69c69b6b29d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
