{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, BatchNormalization, ZeroPadding2D, GlobalMaxPooling2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Resizing\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n",
    "SIZE=224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_training_curve(history):\n",
    "\t\"\"\"\n",
    "\tDraw training curve\n",
    "\tParameters:\n",
    "\t\thistory - contains loss and accuracy from training\n",
    "\tReturns:\n",
    "\t\tNone\n",
    "\t\"\"\"\n",
    "\tplt.figure(1)\n",
    "\n",
    "\t# History for accuracy\n",
    "\tplt.subplot(211)\n",
    "\tplt.plot(history.history['accuracy'])\n",
    "\tplt.plot(history.history['val_accuracy'])\n",
    "\tplt.title('model accuracy')\n",
    "\tplt.ylabel('accuracy')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\t# History for loss\n",
    "\tplt.subplot(212)\n",
    "\tplt.plot(history.history['loss'])\n",
    "\tplt.plot(history.history['val_loss'])\n",
    "\tplt.title('model loss')\n",
    "\tplt.ylabel('loss')\n",
    "\tplt.xlabel('epoch')\n",
    "\tplt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Open Sans':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Titillium Web':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_to_font(font):\n",
    "    if font == 0:\n",
    "        return b'Alex Brush'\n",
    "    elif font == 1:\n",
    "        return b'Open Sans'\n",
    "    elif font == 2:\n",
    "        return b'Sansation'\n",
    "    elif font == 3:\n",
    "        return b'Titillium Web'\n",
    "    else:\n",
    "        return b'Ubuntu Mono'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_label(set, index):\n",
    "    line = set[index]\n",
    "    max = np.argmax(line)\n",
    "    print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_font(max):\n",
    "     print(num_to_font(max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_photo_from_set(set_x, set_y, index, font):\n",
    "    plt.imshow(set_x[index], cmap='gray')\n",
    "    plt.show()\n",
    "    print_font(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_img(img, bbs, index, size = SIZE):\n",
    "    x1 = int(bbs[0,0,index])\n",
    "    y1 = int(bbs[1,0,index])\n",
    "    x2 = int(bbs[0,1,index])\n",
    "    y2 = int(bbs[1,1,index])\n",
    "    x3 = int(bbs[0,2,index])\n",
    "    y3 = int(bbs[1,2,index])\n",
    "    x4 = int(bbs[0,3,index])\n",
    "    y4 = int(bbs[1,3,index])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "\n",
    "    cropped = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    # _, cropped = cv2.threshold(cropped,127,255,cv2.THRESH_TRIANGLE)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.resize(cropped, (size, size), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    # cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    # # print(cropped.shape)\n",
    "    cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    # plt.imshow(cropped, cmap='gray')\n",
    "    # plt.show()\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def create_dirs(main_directory):\n",
    "    Path(main_directory).mkdir(parents=True, exist_ok=True)\n",
    "    Path(main_directory+'/Alex Brush').mkdir(parents=True, exist_ok=True)\n",
    "    Path(main_directory+'/Titillium Web').mkdir(parents=True, exist_ok=True)\n",
    "    Path(main_directory+'/Sansation').mkdir(parents=True, exist_ok=True)\n",
    "    Path(main_directory+'/Open Sans').mkdir(parents=True, exist_ok=True)\n",
    "    Path(main_directory+'/Ubuntu Mono').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(db, im):\n",
    "    img  = db['data'][im][:]\n",
    "    fonts = db['data'][im].attrs['font']\n",
    "    txts = db['data'][im].attrs['txt']\n",
    "    charBBs = db['data'][im].attrs['charBB']\n",
    "    wordBBs = db['data'][im].attrs['wordBB']\n",
    "    return img, fonts, txts, charBBs, wordBBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_num_or_letter(inp):\n",
    "    res= ((inp >= ord('a') and inp <= ord('z')) or (inp >= ord('A') and inp <= ord('Z'))) or (inp>=ord('0') and inp<=ord('9'))\n",
    "    # print(chr(inp)+\"=\"+str(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save(img, BBs, indx, size, curr_font, im, num, append_not_save=False, folder='main_directory/'):\n",
    "    cropped = prepare_img(img, BBs, indx, size)\n",
    "    path = folder+curr_font.decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg' \n",
    "    if not append_not_save:\n",
    "        tf.keras.utils.save_img(path,cropped)\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = h5py.File(FILE_NAME, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(db, size: int):   \n",
    "    create_dirs('main_directory')\n",
    "    im_names = list(db['data'].keys())\n",
    "    num = 0\n",
    "    for i in tqdm(range(0, len(im_names)-1)):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg' \n",
    "            # print(path)\n",
    "            tf.keras.utils.save_img(path,cropped)\n",
    "            num+=1\n",
    "            # train_x.append(cropped)\n",
    "            # train_y.append(font_to_num(fonts[font_indx]))\n",
    "            \n",
    "            # plt.imshow(cropped, cmap='gray')\n",
    "            # plt.show()\n",
    "            # print(fonts[font_indx])\n",
    "            for k in range(0, len(txts[j])):\n",
    "                if(is_num_or_letter(txts[j][k])):\n",
    "                    cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                    path = 'main_directory/'+fonts[font_indx].decode('UTF-8')+'/'+im+'_'+str(num)+'.jpg'\n",
    "                    # print(path)\n",
    "                    tf.keras.utils.save_img(path,cropped)\n",
    "                    num+=1\n",
    "                    # train_x.append(cropped)\n",
    "                    # train_y.append(font_to_num(fonts[font_indx]))\n",
    "                char_indx+=1\n",
    "                    # plt.imshow(cropped, cmap='gray')\n",
    "                    # plt.show()\n",
    "                    # print(fonts[font_indx])\n",
    "            font_indx += len(txts[j])\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 997/997 [02:33<00:00,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from download_h5py_db import download_h5py_db\n",
    "if not Path(\"main_directory\").exists():\n",
    "    download_h5py_db()\n",
    "    get_data_set(db, SIZE)\n",
    "# train_x, train_y = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 36011 files [00:48, 735.62 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"main_directory/\", # The location of dataset\n",
    "                   output=\"main_directory_splitted\", # The output location\n",
    "                   seed=42, # The number of seed\n",
    "                   ratio=(.8, .1, .1), # The ratio of splited dataset\n",
    "                   group_prefix=None, # If your dataset contains more than one file like \".jpg\", \".pdf\", etc\n",
    "                   move=False # If you choose to move, turn this into True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def data_augmentation():\n",
    "    datagen =  ImageDataGenerator(\n",
    "        horizontal_flip=True, rotation_range=90, fill_mode='reflect', channel_shift_range=0.8,#\n",
    "         shear_range=15,vertical_flip=False, brightness_range=(0.2, 0.8),# \n",
    "     rescale=1/255, dtype='float32'\n",
    "     #,validation_split=0.25\n",
    "     )\n",
    "    # Path('augmented').mkdir(exist_ok=True)\n",
    "    it = datagen.flow_from_directory('main_directory_splitted/train/', batch_size=18, class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True, seed=1, keep_aspect_ratio=True)\n",
    "    datagen_val =  ImageDataGenerator(\n",
    "     rescale=1/255, dtype='float32'\n",
    "     )\n",
    "    val_it = datagen_val.flow_from_directory('main_directory_splitted/val/', batch_size=18, class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True)\n",
    "    test_it = datagen_val.flow_from_directory('main_directory_splitted/test/', batch_size=18, class_mode='categorical',\n",
    "    #save_to_dir='augmented',\n",
    "     shuffle=True)\n",
    "    return it, val_it,test_it, datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28806 images belonging to 5 classes.\n",
      "Found 3599 images belonging to 5 classes.\n",
      "Found 3606 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "it, val_it,test_it, datagen = data_augmentation()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found 27011 images belonging to 5 classes.\n",
    "Found 9000 images belonging to 5 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen.fit(it, augment=True, seed=0.8, rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "\n",
    "filepath=\"res/top_model.h5\"\n",
    "\n",
    "checkpoint = callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "num_classes = 5\n",
    "input_size= SIZE\n",
    "\n",
    "baseModel = tf.keras.applications.ResNet50(include_top=False, classes=num_classes,\n",
    "                         input_shape=(input_size, input_size, 3),\n",
    "                        weights='imagenet')\n",
    "headModel = baseModel.output\n",
    "headModel = GaussianNoise(0.1)(headModel)\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(256, activation=\"relu\", kernel_regularizer=regularizers.l2(0.01))(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(num_classes, activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)    \n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.00003), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    # if epoch < 5:\n",
    "    #     return lr\n",
    "    # else:\n",
    "    return lr * 0.1 #tf.math.exp(-0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 5.4869 - accuracy: 0.3851\n",
      "Epoch 1: val_loss improved from inf to 4.54289, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 503s 310ms/step - loss: 5.4869 - accuracy: 0.3851 - val_loss: 4.5429 - val_accuracy: 0.4987\n",
      "Epoch 2/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 3.7034 - accuracy: 0.5552\n",
      "Epoch 2: val_loss improved from 4.54289 to 2.92659, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 494s 308ms/step - loss: 3.7034 - accuracy: 0.5552 - val_loss: 2.9266 - val_accuracy: 0.6079\n",
      "Epoch 3/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 2.4269 - accuracy: 0.6188\n",
      "Epoch 3: val_loss improved from 2.92659 to 1.92568, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 528s 330ms/step - loss: 2.4269 - accuracy: 0.6188 - val_loss: 1.9257 - val_accuracy: 0.6610\n",
      "Epoch 4/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 1.6895 - accuracy: 0.6609\n",
      "Epoch 4: val_loss improved from 1.92568 to 1.43146, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 526s 328ms/step - loss: 1.6895 - accuracy: 0.6609 - val_loss: 1.4315 - val_accuracy: 0.6852\n",
      "Epoch 5/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 1.2922 - accuracy: 0.6987\n",
      "Epoch 5: val_loss improved from 1.43146 to 1.15844, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 531s 332ms/step - loss: 1.2922 - accuracy: 0.6987 - val_loss: 1.1584 - val_accuracy: 0.7052\n",
      "Epoch 6/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 1.0558 - accuracy: 0.7269\n",
      "Epoch 6: val_loss improved from 1.15844 to 0.94543, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 533s 333ms/step - loss: 1.0558 - accuracy: 0.7269 - val_loss: 0.9454 - val_accuracy: 0.7422\n",
      "Epoch 7/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.8959 - accuracy: 0.7470\n",
      "Epoch 7: val_loss improved from 0.94543 to 0.80994, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 525s 328ms/step - loss: 0.8959 - accuracy: 0.7470 - val_loss: 0.8099 - val_accuracy: 0.7683\n",
      "Epoch 8/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.7807 - accuracy: 0.7671\n",
      "Epoch 8: val_loss improved from 0.80994 to 0.74832, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 539s 336ms/step - loss: 0.7807 - accuracy: 0.7671 - val_loss: 0.7483 - val_accuracy: 0.7655\n",
      "Epoch 9/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.6972 - accuracy: 0.7806\n",
      "Epoch 9: val_loss improved from 0.74832 to 0.67519, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 563s 352ms/step - loss: 0.6972 - accuracy: 0.7806 - val_loss: 0.6752 - val_accuracy: 0.7719\n",
      "Epoch 10/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.6280 - accuracy: 0.7968\n",
      "Epoch 10: val_loss improved from 0.67519 to 0.62033, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 540s 337ms/step - loss: 0.6280 - accuracy: 0.7968 - val_loss: 0.6203 - val_accuracy: 0.7897\n",
      "Epoch 11/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.8053\n",
      "Epoch 11: val_loss improved from 0.62033 to 0.60891, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 509s 318ms/step - loss: 0.5781 - accuracy: 0.8053 - val_loss: 0.6089 - val_accuracy: 0.7883\n",
      "Epoch 12/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8182\n",
      "Epoch 12: val_loss improved from 0.60891 to 0.57666, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 500s 312ms/step - loss: 0.5334 - accuracy: 0.8182 - val_loss: 0.5767 - val_accuracy: 0.8083\n",
      "Epoch 13/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.8247\n",
      "Epoch 13: val_loss improved from 0.57666 to 0.56508, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 493s 308ms/step - loss: 0.5034 - accuracy: 0.8247 - val_loss: 0.5651 - val_accuracy: 0.8041\n",
      "Epoch 14/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.4699 - accuracy: 0.8347\n",
      "Epoch 14: val_loss improved from 0.56508 to 0.55509, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 498s 311ms/step - loss: 0.4699 - accuracy: 0.8347 - val_loss: 0.5551 - val_accuracy: 0.8013\n",
      "Epoch 15/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.4479 - accuracy: 0.8413\n",
      "Epoch 15: val_loss improved from 0.55509 to 0.51576, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 497s 310ms/step - loss: 0.4479 - accuracy: 0.8413 - val_loss: 0.5158 - val_accuracy: 0.8149\n",
      "Epoch 16/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.4217 - accuracy: 0.8512\n",
      "Epoch 16: val_loss improved from 0.51576 to 0.50139, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 513s 320ms/step - loss: 0.4217 - accuracy: 0.8512 - val_loss: 0.5014 - val_accuracy: 0.8197\n",
      "Epoch 17/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.3924 - accuracy: 0.8598\n",
      "Epoch 17: val_loss did not improve from 0.50139\n",
      "1601/1601 [==============================] - 529s 330ms/step - loss: 0.3924 - accuracy: 0.8598 - val_loss: 0.5289 - val_accuracy: 0.8130\n",
      "Epoch 18/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.3787 - accuracy: 0.8663\n",
      "Epoch 18: val_loss improved from 0.50139 to 0.48607, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 539s 336ms/step - loss: 0.3787 - accuracy: 0.8663 - val_loss: 0.4861 - val_accuracy: 0.8344\n",
      "Epoch 19/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.3659 - accuracy: 0.8685\n",
      "Epoch 19: val_loss did not improve from 0.48607\n",
      "1601/1601 [==============================] - 520s 324ms/step - loss: 0.3659 - accuracy: 0.8685 - val_loss: 0.5377 - val_accuracy: 0.8102\n",
      "Epoch 20/20\n",
      "1601/1601 [==============================] - ETA: 0s - loss: 0.3510 - accuracy: 0.8769\n",
      "Epoch 20: val_loss improved from 0.48607 to 0.47209, saving model to res\\top_model.h5\n",
      "1601/1601 [==============================] - 525s 328ms/step - loss: 0.3510 - accuracy: 0.8769 - val_loss: 0.4721 - val_accuracy: 0.8316\n"
     ]
    }
   ],
   "source": [
    "# model.fit(X_train, Y_train, batch_size=16, epochs=20)\n",
    "# datagen.fit(X_train)\n",
    "# if not os.path.isfile('model_res.h5'):\n",
    "history = model.fit(it, epochs=20, shuffle=True, validation_data=val_it, verbose=1\n",
    "            ,callbacks=callbacks_list\n",
    "            )\n",
    "# else:\n",
    "#   model = tf.keras.models.load_model('model_res.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 18s 89ms/step - loss: 0.5132 - accuracy: 0.8242\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.5132091641426086 / Test accuracy: 0.8241819143295288\n"
     ]
    }
   ],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_training_curve(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('model_res')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('res//top_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/249 [00:00<00:59,  4.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 3 2]\n",
      "[0 0 1 0 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/249 [00:00<00:40,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 2]\n",
      "[4 0 0 0 0 2 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/249 [00:00<00:26,  9.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4]\n",
      "[0 0 0 0 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 10/249 [00:01<00:25,  9.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4]\n",
      "[3 3 3 3]\n",
      "[2 2 3 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 12/249 [00:01<00:25,  9.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 4]\n",
      "[0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 14/249 [00:01<00:26,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n",
      "[4 4 2 4 2 2 0 2 4 0 4 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17/249 [00:02<00:25,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 0 0]\n",
      "[4 4 4 4 4]\n",
      "[1 1 1 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 20/249 [00:02<00:24,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 4]\n",
      "[0 0 0 0]\n",
      "[2 3 2 2 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 22/249 [00:02<00:26,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1]\n",
      "[2 2 2 2 2 2 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 24/249 [00:02<00:24,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2]\n",
      "[4 4 4 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 26/249 [00:03<00:25,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 2 2 2]\n",
      "[0 0 0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 28/249 [00:03<00:28,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 4]\n",
      "[1 3 3 3 3 3 0 3 0 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 30/249 [00:03<00:28,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 0 0 0 2 0]\n",
      "[3 3 3 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 32/249 [00:03<00:29,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[4 4 0 4 4 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 34/249 [00:04<00:27,  7.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 0 4 4]\n",
      "[0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 37/249 [00:04<00:19, 10.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0]\n",
      "[4 4 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 41/249 [00:04<00:14, 14.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 3 1 1 0]\n",
      "[0 0 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 42/249 [00:04<00:23,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 2 2 2 1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m test_x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(test_x, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m     31\u001b[0m \u001b[39m# # print(test_x)\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m reses \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(test_x, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     33\u001b[0m \u001b[39m# # print(reses)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m maxes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(reses, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2211\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   2212\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2213\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2214\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2217\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[0;32m   2218\u001b[0m         )\n\u001b[1;32m-> 2220\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   2221\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   2222\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   2223\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   2224\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   2225\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   2226\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   2227\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   2228\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   2229\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2230\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[0;32m   2231\u001b[0m )\n\u001b[0;32m   2233\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1581\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1582\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1261\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1263\u001b[0m     x,\n\u001b[0;32m   1264\u001b[0m     y,\n\u001b[0;32m   1265\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1266\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1267\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1268\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1269\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1270\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1271\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1272\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1273\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1274\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m   1275\u001b[0m )\n\u001b[0;32m   1277\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1279\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\engine\\data_adapter.py:347\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    344\u001b[0m         flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    345\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 347\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[0;32m    349\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2245\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2212\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_map\u001b[39m(\u001b[39mself\u001b[39m, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2213\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2214\u001b[0m \n\u001b[0;32m   2215\u001b[0m \u001b[39m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   2244\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2245\u001b[0m   \u001b[39mreturn\u001b[39;00m FlatMapDataset(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5484\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5482\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5483\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m-> 5484\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   5485\u001b[0m     map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[0;32m   5486\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5487\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   5488\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5489\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_get_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    272\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2610\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   2602\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2603\u001b[0m \n\u001b[0;32m   2604\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2608\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2609\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2610\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2611\u001b[0m       \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2612\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2613\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2576\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2574\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2575\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2576\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2577\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   2578\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2579\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1288\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1282\u001b[0m   \u001b[39m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m   func_graph\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mextend(\n\u001b[0;32m   1284\u001b[0m       func_graph\u001b[39m.\u001b[39mcapture(x)\n\u001b[0;32m   1285\u001b[0m       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m flatten(func_graph\u001b[39m.\u001b[39mstructured_outputs)\n\u001b[0;32m   1286\u001b[0m       \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1288\u001b[0m   func_graph\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m variables\n\u001b[0;32m   1290\u001b[0m \u001b[39mif\u001b[39;00m add_control_dependencies:\n\u001b[0;32m   1291\u001b[0m   func_graph\u001b[39m.\u001b[39mcontrol_outputs\u001b[39m.\u001b[39mextend(deps_control_manager\u001b[39m.\u001b[39mops_which_must_run)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:585\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[1;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m r\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39mbuilding_function:\n\u001b[0;32m    579\u001b[0m   \u001b[39m# There may be many stateful ops in the graph. Adding them as\u001b[39;00m\n\u001b[0;32m    580\u001b[0m   \u001b[39m# control inputs to each function output could create excessive\u001b[39;00m\n\u001b[0;32m    581\u001b[0m   \u001b[39m# control edges in the graph. Thus we create an intermediate No-op\u001b[39;00m\n\u001b[0;32m    582\u001b[0m   \u001b[39m# to chain the control dependencies between stateful ops and\u001b[39;00m\n\u001b[0;32m    583\u001b[0m   \u001b[39m# function outputs.\u001b[39;00m\n\u001b[0;32m    584\u001b[0m   \u001b[39mif\u001b[39;00m idx \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 585\u001b[0m     control_output_op \u001b[39m=\u001b[39m control_flow_ops\u001b[39m.\u001b[39;49mno_op()\n\u001b[0;32m    586\u001b[0m     control_output_op\u001b[39m.\u001b[39m_set_attr(\u001b[39m\"\u001b[39m\u001b[39m_acd_function_control_output\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    587\u001b[0m                                 attr_value_pb2\u001b[39m.\u001b[39mAttrValue(b\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m    588\u001b[0m     control_output_op\u001b[39m.\u001b[39m_add_control_inputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mops_which_must_run)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_control_flow_ops.py:509\u001b[0m, in \u001b[0;36mno_op\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 509\u001b[0m   _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m    510\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mNoOp\u001b[39;49m\u001b[39m\"\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    511\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m    512\u001b[0m   _result \u001b[39m=\u001b[39m _dispatch\u001b[39m.\u001b[39mdispatch(\n\u001b[0;32m    513\u001b[0m         no_op, (), \u001b[39mdict\u001b[39m(name\u001b[39m=\u001b[39mname)\n\u001b[0;32m    514\u001b[0m       )\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\simon\\anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1939\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1937\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39m_c_graph\u001b[39m.\u001b[39mget() \u001b[39mas\u001b[39;00m c_graph:\n\u001b[1;32m-> 1939\u001b[0m   op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(c_graph,\n\u001b[0;32m   1940\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1941\u001b[0m                                               compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1942\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1943\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "create_dirs('test_set')\n",
    "size=SIZE\n",
    "im_names = list(db['data'].keys())\n",
    "num = 0\n",
    "prediction_arr=[]\n",
    "test_y = []\n",
    "\n",
    "for i in tqdm(range(0, int((len(im_names)-1)/4))):\n",
    "    im = im_names[i]\n",
    "    img, fonts, txts, charBBs, wordBBs = get_image_data(db, im)\n",
    "    font_indx = 0 \n",
    "    char_indx = 0\n",
    "    curr_font = fonts[font_indx]\n",
    "    # print(im)\n",
    "    for j in range(0, int(len(txts)/4)):\n",
    "        if(j%8==0): \n",
    "            test_x = [] \n",
    "            cropped = crop_and_save(img, wordBBs, j, size, curr_font, im, num, False, 'test_set/')\n",
    "            test_x.append(cropped)\n",
    "            # test_y.append(font_to_num(curr_font))\n",
    "            num+=1            \n",
    "            for k in range(0, len(txts[j])):\n",
    "                # if(is_num_or_letter(txts[j][k])):\n",
    "                cropped = crop_and_save(img, charBBs, char_indx, size, curr_font, im, num, False, 'test_set/')\n",
    "                test_x.append(cropped)\n",
    "                    # test_y.append(font_to_num(curr_font))\n",
    "                num+=1\n",
    "                char_indx+=1\n",
    "            test_x = np.asarray(test_x, dtype=np.float32)\n",
    "            # # print(test_x)\n",
    "            reses = model.predict(test_x, verbose=0)\n",
    "            # # print(reses)\n",
    "            maxes = np.argmax(reses, axis=1)\n",
    "            # print(np.bincount(maxes))\n",
    "            prediction = np.bincount(maxes)\n",
    "            prediction = np.argwhere(prediction==prediction.max())\n",
    "            if (len(prediction)>1):\n",
    "                sum_p = reses.sum(axis=0)\n",
    "                prediction = sum_p.argmax()\n",
    "\n",
    "                if(font_to_num(curr_font)!=prediction):\n",
    "                    # print(sum_p)\n",
    "                    reses_n = normalize(reses, axis=1, norm='l1')\n",
    "                    maxes_n = np.argmax(reses_n, axis=1)\n",
    "                    # print(np.bincount(maxes))\n",
    "                    prediction = np.bincount(maxes_n)\n",
    "                    prediction = np.argmax(prediction)\n",
    "                    if(font_to_num(curr_font)!=prediction):\n",
    "                        sum_p = np.sum(reses, axis=0)\n",
    "                        prediction = sum_p.argmax()\n",
    "                    # # print(reses[0]/np.sum(reses, axis=1)[0])\n",
    "                    #     print(maxes)\n",
    "                    # print(prediction)\n",
    "                    # plt.imshow(test_x[0])\n",
    "                    # plt.show()\n",
    "                    # print(prediction)\n",
    "                    # print(font_to_num(fonts[font_indx]))\n",
    "            for k in range(0, len(txts[j])):\n",
    "                test_y.append(font_to_num(fonts[font_indx]))\n",
    "                prediction_arr.append(prediction.item())\n",
    "                # print(prediction.item())\n",
    "            # if(font_to_num(curr_font)!=prediction):\n",
    "            #     plt.imshow(test_x[0])\n",
    "            #     plt.show()\n",
    "            #     print(maxes)\n",
    "            #     print(reses)\n",
    "            #     print(prediction)\n",
    "            #     print(font_to_num(fonts[font_indx]))\n",
    "            #     print('----------------------')\n",
    "            # print(num_to_font(prediction))\n",
    "            # print(test_x)\n",
    "            # print(str(np.bincount(maxes).argmax())+\"-\"+str(font_to_num(fonts[font_indx])))\n",
    "            # print(np.bincount(maxes).argmax())\n",
    "        else:\n",
    "            char_indx+=len(txts[j])\n",
    "        font_indx += len(txts[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "837\n",
      "837\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction_arr))\n",
    "print(len(test_y))\n",
    "# test_x = np.asarray(test_x, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred=np.argmax(prediction_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Alex Brush       0.75      0.98      0.85       169\n",
      "    Open Sans       0.86      0.85      0.85       142\n",
      "    Sansation       0.94      0.77      0.84       208\n",
      "Titillium Web       0.91      0.82      0.86       158\n",
      "  Ubuntu Mono       0.96      0.98      0.97       160\n",
      "\n",
      "     accuracy                           0.88       837\n",
      "    macro avg       0.88      0.88      0.88       837\n",
      " weighted avg       0.89      0.88      0.88       837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "labels=['Alex Brush','Open Sans','Sansation','Titillium Web','Ubuntu Mono']\n",
    "print(classification_report(test_y, prediction_arr, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003\n"
     ]
    }
   ],
   "source": [
    "print(len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_arr = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(prediction_arr, axis=1)\n",
    "# y_test=np.argmax(test_y_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = np.asarray(test_y, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_cat = np_utils.to_categorical(test_y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1003,)\n"
     ]
    }
   ],
   "source": [
    "# print(test_y)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "labels=['Alex Brush','Open Sans','Titillium Web','Sansation','Ubuntu Mono']\n",
    "print(classification_report(test_y, prediction_arr, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for im in test_x:\n",
    "#     tf.keras.utils.save_img('path',cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1036 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "dg =  ImageDataGenerator(\n",
    "     rescale=1/255, dtype='float32',\n",
    "     )\n",
    "t = dg.flow_from_directory('test_set', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 7s 150ms/step - loss: 0.4039 - accuracy: 0.8620\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40388888120651245, 0.8619691133499146]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(prediction_arr, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Alex Brush       0.80      0.93      0.86       204\n",
      "Titillium Web       0.14      0.12      0.13       195\n",
      "    Sansation       0.73      0.68      0.70       248\n",
      "    Open Sans       0.13      0.14      0.13       168\n",
      "  Ubuntu Mono       0.81      0.82      0.81       188\n",
      "\n",
      "     accuracy                           0.56      1003\n",
      "    macro avg       0.52      0.54      0.53      1003\n",
      " weighted avg       0.54      0.56      0.55      1003\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_y, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3850 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_t =  ImageDataGenerator(\n",
    "     rescale=1/255, dtype='float32'\n",
    "     )\n",
    "t_it = datagen_t.flow_from_directory('check_test', batch_size=18, class_mode='categorical',shuffle=False\n",
    "#save_to_dir='augmented',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 15s 68ms/step - loss: 0.6127 - accuracy: 0.7730\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(t_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/214 [==============================] - 14s 64ms/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(t_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the class with highest probability for each sample\n",
    "y_pred = np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Alex Brush       0.88      0.91      0.90       818\n",
      "Titillium Web       0.55      0.60      0.57       547\n",
      "    Sansation       0.74      0.72      0.73       910\n",
      "    Open Sans       0.75      0.61      0.68       732\n",
      "  Ubuntu Mono       0.86      0.95      0.90       843\n",
      "\n",
      "     accuracy                           0.77      3850\n",
      "    macro avg       0.76      0.76      0.76      3850\n",
      " weighted avg       0.77      0.77      0.77      3850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(t_it.classes, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_arr_cat = np_utils.to_categorical(prediction_arr, 5)\n",
    "# test_y_cat = np_utils.to_categorical(test_y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# m = tf.keras.metrics.AUC()\n",
    "\n",
    "# m.update_state(test_y, prediction_arr) # assuming both have shape (N,)\n",
    "\n",
    "# r = m.result().numpy()\n",
    "\n",
    "# print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_true = test_y_cat\n",
    "# y_pred = prediction_arr\n",
    "# kacc = tf.keras.metrics.Accuracy()\n",
    "# _ = kacc.update_state(y_true, y_pred)\n",
    "# print(f'Keras Accuracy acc: {kacc.result().numpy()*100:.3}')\n",
    "\n",
    "# kbacc = tf.keras.metrics.BinaryAccuracy()\n",
    "# _ = kbacc.update_state(y_true, y_pred)\n",
    "# print(f'Keras BinaryAccuracy acc: {kbacc.result().numpy()*100:.3}')\n",
    "\n",
    "# print(f'SkLearn acc: {accuracy_score(y_true, y_pred)*100:.3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
