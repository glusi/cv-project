{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision - Project\n",
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "import h5py, requests, os\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG_SIZE = (64, 64)\n",
    "# IMG_SHAPE = IMG_SIZE + (3,)\n",
    "# base_model = tf.keras.applications.resnet(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZIP_PATH = \"https://drive.google.com/drive/folders/1jzHYpTwywUYA53nMGHVROSuVO14hEueq?usp=sharing/\"\n",
    "FILE_NAME =\"SynthText_train.h5\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n",
    "tf.keras.backend.clear_session()\n",
    "SIZE = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_points(points, center):\n",
    "    # calculate the angle of each point from the center point\n",
    "    angles = np.arctan2(points[:, 1] - center[1], points[:, 0] - center[0])\n",
    "    # sort the points by angle\n",
    "    sorted_points = points[np.argsort(angles)]\n",
    "    return sorted_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_points(image, points, color=(255, 0, 0), radius=3):\n",
    "    # create a copy of the image\n",
    "    img = image.copy()\n",
    "    # iterate over the points and draw them on the image\n",
    "    for point in points:\n",
    "        cv2.circle(img, tuple(map(int, point)), radius, color, -1)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bb(img, bbs, indx):\n",
    "    x1 = int(bbs[0,0,indx])\n",
    "    y1 = int(bbs[1,0,indx])\n",
    "    x2 = int(bbs[0,1,indx])\n",
    "    y2 = int(bbs[1,1,indx])\n",
    "    x3 = int(bbs[0,2,indx])\n",
    "    y3 = int(bbs[1,2,indx])\n",
    "    x4 = int(bbs[0,3,indx])\n",
    "    y4 = int(bbs[1,3,indx])\n",
    "    # calculate bounding rectangle\n",
    "    top_left_x = max(0, min([x1,x2,x3,x4]))\n",
    "    top_left_y = max(0, min([y1,y2,y3,y4]))\n",
    "    bot_right_x = max(0, max([x1,x2,x3,x4]))\n",
    "    bot_right_y = max(0, max([y1,y2,y3,y4]))\n",
    "    points = np.float32([[x1, y1], [x2, y2], [x3, y3], [x4, y4]])\n",
    "    \n",
    "    # create an empty image with the same shape as the input image\n",
    "    mask = np.zeros_like(img[:,:,0])\n",
    "    # create a list of the bounding box points in the correct format\n",
    "    bounding_box = np.array([points], dtype=np.int32)\n",
    "    # fill the area inside the bounding box with white\n",
    "    cv2.fillPoly(mask, bounding_box, 1)\n",
    "    # apply the mask to the image\n",
    "    ####res = cv2.bitwise_and(img, mask)\n",
    "    # try1 = np.array(np.where(mask == 255, 255, 0), dtype=np.uint8)\n",
    "    # print(x)\n",
    "    # inv_mask = cv2.bitwise_not(mask)\n",
    "    # res2 = cv2.bitwise_and(img, inv_mask)\n",
    "    # bb2 = np.int32([[top_left_x, bot_right_y], [bot_right_x, bot_right_y],[bot_right_x,top_left_y], [top_left_x,top_left_y]])\n",
    "    # print(bb2)\n",
    "    # mask2 = np.zeros_like(img)\n",
    "    # # bb2 = np.array(frame, dtype=np.int32)\n",
    "    # cv2.fillPoly(mask2, bb2, (255, 255, 255))\n",
    "    mask = mask[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "\n",
    "    #res = img[top_left_y:bot_right_y+1, top_left_x:bot_right_x+1]\n",
    "    #flipping\n",
    "    \"\"\"\"if(x2 < x1):\n",
    "        res = cv2.flip(res, 1)\n",
    "    if(y2 < y1):\n",
    "        res = cv2.flip(res, 0)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()\n",
    "    print(mask.shape)\"\"\"\n",
    "    return res, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def font_to_num(font):\n",
    "    if font == b'Alex Brush':\n",
    "        return 0\n",
    "    elif font == b'Titillium Web':\n",
    "        return 1\n",
    "    elif font == b'Sansation':\n",
    "        return 2\n",
    "    elif font == b'Open Sans':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img, bbs, index, size):\n",
    "    cropped, mask = get_bb(img, bbs, index)\n",
    "    # cropped = cv2.GaussianBlur(np.array(cropped), (3, 3), 0)\n",
    "    # plt.imshow(cropped)\n",
    "    # plt.show()\n",
    "    # cropped = tf.image.convert_image_dtype(cropped, tf.float32)\n",
    "    \n",
    "    # cropped = tf.cast(cropped, tf.int32)\n",
    "    # plt.imshow(cropped)\n",
    "    # plt.show()\n",
    "    # gray_mask = tf.image.rgb_to_grayscale(mask)\n",
    "    # print(mask.shape)\n",
    "    # print(cropped.shape)\n",
    "    cropped = tf.image.rgb_to_grayscale(cropped)\n",
    "    res = tf.cast(cropped, tf.float32) /255.0\n",
    "    # mask = tf.cast(mask, tf.float32)\n",
    "    # print(cropped.shape)\n",
    "    # cropped = tf.expand_dims(cropped, 0)\n",
    "    # mask = tf.expand_dims(mask, 2)\n",
    "    # mask = tf.image.resize_with_pad(mask, size, size)\n",
    "    # print(cropped.shape)\n",
    "    # print(mask.shape)\n",
    "    # cropped = tf.image.sobel_edges(cropped)\n",
    "    # cropped = cropped**2\n",
    "    # # print(cropped.shape)\n",
    "    # cropped = tf.math.reduce_sum(cropped,axis=-1) # sum all magnitude components\n",
    "    # cropped = tf.sqrt(cropped) # this is the image tensor you want\n",
    "    # # print(cropped[0, :, :, :].shape)\n",
    "    # # plt.imshow(cropped[0, :, :, :], cmap='gray')\n",
    "    # # plt.show()\n",
    "    # cropped = cropped[0, :, :, :]\n",
    "    # plt.imshow(cropped, cmap ='gray')\n",
    "    # plt.show()\n",
    "    # plt.imshow(mask, cmap ='gray')\n",
    "    # plt.show()\n",
    "    # print(cropped.shape)\n",
    "    # print(gray_mask.shape)\n",
    "#    cropped = tf.cast(cropped, tf.int32)\n",
    "    # mask = tf.cast(mask, tf.float32)\n",
    "    # print(gray_mask)\n",
    "    # res = tf.multiply(cropped, mask)\n",
    "    \n",
    "    # plt.imshow(mask, cmap ='gray')\n",
    "    # plt.show()\n",
    "    res = tf.image.resize_with_pad(res, size, size)\n",
    "    # plt.imshow(res, cmap ='gray')\n",
    "    # plt.show()\n",
    "    return res#res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(size: int):\n",
    "    db = h5py.File(FILE_NAME, 'r')\n",
    "    im_names = list(db['data'].keys())\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for i in range(0, len(im_names)-1):\n",
    "        im = im_names[i]\n",
    "        img  = db['data'][im][:]\n",
    "        fonts = db['data'][im].attrs['font']\n",
    "        txts = db['data'][im].attrs['txt']\n",
    "        charBBs = db['data'][im].attrs['charBB']\n",
    "        wordBBs = db['data'][im].attrs['wordBB']\n",
    "        font_indx = 0 \n",
    "        char_indx = 0\n",
    "        # print(im)\n",
    "        for j in range(0, len(txts)):\n",
    "            cropped = prepare_img(img, wordBBs, j, size)\n",
    "            train_x.append(cropped)\n",
    "            train_y.append(font_to_num(fonts[font_indx]))\n",
    "            font_indx += len(txts[j])\n",
    "            #plt.imshow(cropped)\n",
    "            #plt.show()\n",
    "            for k in range(0, len(txts[j])):\n",
    "                cropped = prepare_img(img, charBBs, char_indx, size)\n",
    "                train_x.append(cropped)\n",
    "                train_y.append(font_to_num(fonts[char_indx]))\n",
    "                char_indx+=1\n",
    "                #plt.imshow(cropped)\n",
    "                #plt.show()\n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_data_set(SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.asarray(train_x, dtype=\"float\") / 255.0\n",
    "plt.imshow(train_x[3], cmap='gray')\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut the set for train and validation\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 5)\n",
    "Y_test = np_utils.to_categorical(y_test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential([\n",
    "#   tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "#   tf.keras.layers.RandomRotation(0.2),\n",
    "# ])\n",
    "# print(x_train.shape)\n",
    "# SIZE=128\n",
    "from keras.layers import RandomFlip, RandomRotation, Masking\n",
    "model = Sequential()\n",
    "\n",
    "model.add(RandomFlip(\"horizontal_and_vertical\"))\n",
    "# model.add(RandomRotation(0.1))\n",
    "model.add(Convolution2D(32, (5, 5), strides=(2,2), activation='relu', padding='same', input_shape=(SIZE,SIZE,1)))\n",
    "model.add(Convolution2D(32, (5, 5), strides=(2,2), activation='relu', padding='same'))\n",
    "# model.add(Masking(mask_value=0, input_shape=(SIZE, SIZE)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(x_train)\n",
    "Y_train = np.array(Y_train)\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# plt.imshow(X_train[2], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.array(x_train, dtype='uint8')\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, batch_size=10, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(x_test)\n",
    "#np.random.shuffle(Y_test)\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = model.predict(X_train[:7])\n",
    "# print(res) 0.3924284279346466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Y_train[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model \n",
    "#tf.keras.backend.clear_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "017718ff8815c2e28200b0ec15712f9c3f1df2ede3aa8445637a6e1eb80e7347"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
